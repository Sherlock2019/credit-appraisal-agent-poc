# agents/credit_appraisal/model_utils.py
from __future__ import annotations

import json
import os
import re
import time
import shutil
from typing import Dict, Any, List, Optional, Tuple

import joblib
import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score

# ───────────────────────────────────────────────────────────────
# Paths & constants
# ───────────────────────────────────────────────────────────────

BASE_DIR = os.path.dirname(__file__)
MODELS_DIR = os.path.join(BASE_DIR, "models")
TRAINED_DIR = os.path.join(MODELS_DIR, "trained")
PRODUCTION_DIR = os.path.join(MODELS_DIR, "production")

os.makedirs(TRAINED_DIR, exist_ok=True)
os.makedirs(PRODUCTION_DIR, exist_ok=True)

PRODUCTION_MODEL_FILENAME = "credit_model.joblib"
PRODUCTION_META_FILENAME = "meta.json"

PRODUCTION_MODEL_PATH = os.path.join(PRODUCTION_DIR, PRODUCTION_MODEL_FILENAME)
PRODUCTION_META_PATH = os.path.join(PRODUCTION_DIR, PRODUCTION_META_FILENAME)

# ───────────────────────────────────────────────────────────────
# File helpers
# ───────────────────────────────────────────────────────────────

def _read_json(path: str, default: Any = None) -> Any:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return default

def _write_json(path: str, obj: Any) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

# ───────────────────────────────────────────────────────────────
# Utilities
# ───────────────────────────────────────────────────────────────

_DROP_LIKE = {
    "application_id", "ai_decision", "human_decision", "decision",
    "rule_reasons", "label", "target", "explanation",
    "proposed_consolidation_loan", "proposed_loan_option",
    "customer_type", "currency_code", "created_at",
    "session_user_name", "session_user_email", "session_flagged"
}

def _slug(s: str) -> str:
    s = s.strip().lower()
    s = re.sub(r"[^a-z0-9]+", "-", s)
    return s.strip("-")[:40] or "user"

def _now_ts() -> str:
    return time.strftime("%Y%m%d-%H%M%S")

def _sidecar_json_path(joblib_path: str) -> str:
    base, _ = os.path.splitext(joblib_path)
    return base + ".json"

def _coerce_label_series(df: pd.DataFrame) -> pd.Series:
    if "human_decision" in df.columns:
        y = df["human_decision"].astype(str).str.lower().map({"approved": 1, "denied": 0})
        if y.isna().any():
            raise ValueError("human_decision must contain only 'approved' or 'denied'.")
        return y.astype(int)

    for c in ("label", "target"):
        if c in df.columns:
            y = df[c]
            if not set(pd.unique(y)).issubset({0, 1}):
                raise ValueError(f"{c} must be binary 0/1.")
            return y.astype(int)

    raise ValueError(
        "Feedback CSV must contain 'human_decision' (approved/denied) "
        "or a binary column 'label'/'target'."
    )

def _select_feature_columns(df: pd.DataFrame) -> List[str]:
    num_df = df.select_dtypes(include=[np.number]).copy()
    feat_cols = [c for c in num_df.columns if c not in _DROP_LIKE]
    feat_cols = sorted(feat_cols)
    if not feat_cols:
        raise ValueError("No numeric features available.")
    return feat_cols

def _load_feedback_csvs(paths: List[str]) -> pd.DataFrame:
    frames: List[pd.DataFrame] = [pd.read_csv(p) for p in paths]
    df = pd.concat(frames, ignore_index=True)
    df = df.dropna(axis=1, how="all")
    return df

def _infer_dti(df: pd.DataFrame) -> pd.Series:
    if "DTI" in df.columns:
        return pd.to_numeric(df["DTI"], errors="coerce").fillna(0.0).clip(0, 10)
    inc = pd.to_numeric(df.get("income", 0.0), errors="coerce").replace(0, np.nan)
    debt = pd.to_numeric(df.get("existing_debt", 0.0), errors="coerce").fillna(0.0)
    dti = (debt / inc).fillna(0.0)
    return dti.clip(0, 10)

# ───────────────────────────────────────────────────────────────
# Public API: training / registry
# ───────────────────────────────────────────────────────────────

def fit_candidate_on_feedback(
    feedback_csvs: List[str],
    user_name: str,
    agent_name: str = "credit_appraisal",
    algo_name: str = "credit_lr",
) -> Dict[str, Any]:
    df = _load_feedback_csvs(feedback_csvs)
    y = _coerce_label_series(df)
    feat_cols = _select_feature_columns(df)

    X = df.reindex(columns=feat_cols, fill_value=0.0)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y if y.nunique() > 1 else None
    )

    if len(pd.unique(y)) < 2:
        raise ValueError("Need at least 2 classes in feedback to train (both approved and denied).")

    pipe = Pipeline(
        steps=[
            ("scaler", StandardScaler(with_mean=False)),
            ("clf", LogisticRegression(max_iter=1000, class_weight="balanced")),
        ]
    )
    pipe.fit(X_train, y_train)

    y_pred = pipe.predict(X_test) if len(X_test) else np.array([])
    try:
        y_proba = pipe.predict_proba(X_test)[:, 1] if len(X_test) else np.array([])
    except Exception:
        y_proba = np.array([])

    acc = float(accuracy_score(y_test, y_pred)) if len(y_pred) else None
    auc = float(roc_auc_score(y_test, y_proba)) if len(y_proba) else None

    ts = _now_ts()
    model_name = f"{algo_name}-{_slug(user_name)}-{_slug(agent_name)}-{ts}.joblib"
    model_path = os.path.join(TRAINED_DIR, model_name)
    meta_path = _sidecar_json_path(model_path)

    blob = {"pipeline": pipe, "features": feat_cols}
    joblib.dump(blob, model_path)

    meta = {
        "version": "1.0",
        "created_at": ts,
        "created_by": user_name,
        "agent_name": agent_name,
        "algo_name": algo_name,
        "model_name": model_name,
        "feature_names": feat_cols,
        "metrics": {
            "accuracy": acc,
            "roc_auc": auc,
            "n_rows": int(len(df)),
            "n_features": int(len(feat_cols)),
        },
        "source": {"feedback_csvs": feedback_csvs},
    }
    _write_json(meta_path, meta)

    return {
        "job_id": ts,
        "model_name": model_name,
        "model_path": model_path,
        "meta_path": meta_path,
        "metrics": meta["metrics"],
        "feature_names": feat_cols,
    }

def list_available_models(kind: str = "trained") -> List[str]:
    if kind == "trained":
        if not os.path.isdir(TRAINED_DIR):
            return []
        return sorted([f for f in os.listdir(TRAINED_DIR) if f.endswith(".joblib")])
    if kind == "production":
        return [PRODUCTION_MODEL_FILENAME] if os.path.exists(PRODUCTION_MODEL_PATH) else []
    raise ValueError("kind must be 'trained' or 'production'")

def promote_to_production(model_name: str) -> Dict[str, Any]:
    src_model_path = os.path.join(TRAINED_DIR, model_name)
    src_meta_path = _sidecar_json_path(src_model_path)
    if not os.path.exists(src_model_path):
        raise FileNotFoundError(f"Trained model not found: {model_name}")

    os.makedirs(PRODUCTION_DIR, exist_ok=True)
    shutil.copyfile(src_model_path, PRODUCTION_MODEL_PATH)

    prod_meta = {"version": "1.0", "promoted_at": _now_ts(), "source": model_name}
    if os.path.exists(src_meta_path):
        src_meta = _read_json(src_meta_path, default={})
        prod_meta["trained_meta"] = {
            k: src_meta.get(k) for k in ("created_at", "created_by", "agent_name", "algo_name", "metrics", "feature_names")
        }
    _write_json(PRODUCTION_META_PATH, prod_meta)
    return {"model_path": PRODUCTION_MODEL_PATH, "meta_path": PRODUCTION_META_PATH}

def get_production_meta() -> Dict[str, Any]:
    if not os.path.exists(PRODUCTION_MODEL_PATH) or not os.path.exists(PRODUCTION_META_PATH):
        return {"has_production": False, "meta": None}
    meta = _read_json(PRODUCTION_META_PATH, default={})
    return {"has_production": True, "meta": meta}

def _load_model_from_path(path: str) -> Dict[str, Any]:
    blob = joblib.load(path)
    if not isinstance(blob, dict) or "pipeline" not in blob:
        blob = {"pipeline": blob, "features": []}
    blob.setdefault("features", [])
    return blob

def load_model_by_name(name: str, kind: str = "trained") -> Dict[str, Any]:
    if kind == "production":
        path = PRODUCTION_MODEL_PATH
        if not os.path.exists(path):
            raise FileNotFoundError("No production model.")
        return _load_model_from_path(path)
    if kind == "trained":
        path = os.path.join(TRAINED_DIR, name)
        if not os.path.exists(path):
            raise FileNotFoundError(f"Trained model not found: {name}")
        return _load_model_from_path(path)
    raise ValueError("kind must be 'trained' or 'production'")

def load_latest_trained_model() -> Optional[Dict[str, Any]]:
    if not os.path.isdir(TRAINED_DIR):
        return None
    candidates = [
        os.path.join(TRAINED_DIR, f)
        for f in os.listdir(TRAINED_DIR)
        if f.endswith(".joblib")
    ]
    if not candidates:
        return None
    latest = max(candidates, key=os.path.getmtime)
    return _load_model_from_path(latest)

# ───────────────────────────────────────────────────────────────
# Back-compat + scoring-time ensure_model
# ───────────────────────────────────────────────────────────────

def ensure_model(df: Optional[pd.DataFrame] = None, *args, **kwargs) -> Tuple[Pipeline, List[str]]:
    """
    Return a (model, feature_cols) tuple ready for predict/predict_proba.

    Behavior:
      • If a production model exists (production/credit_model.joblib), load and return it.
      • Else, build a simple baseline model from `df` (if provided), using numeric columns
        (excluding identifiers). Synthetic labels are created from heuristics to allow
        scoring to function end-to-end.
    """
    # Case 1: production model exists
    if os.path.exists(PRODUCTION_MODEL_PATH):
        blob = _load_model_from_path(PRODUCTION_MODEL_PATH)
        model = blob["pipeline"]
        feature_cols = blob.get("features") or []
        # If saved model didn't store features, infer a safe default
        if not feature_cols and df is not None and isinstance(df, pd.DataFrame):
            feature_cols = _select_feature_columns(df)
        return model, feature_cols

    # Case 2: build a baseline from df
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        # Minimal stub to avoid crashes; train on a dummy 1-col zero array
        pipe = Pipeline(
            steps=[("scaler", StandardScaler(with_mean=False)),
                   ("clf", LogisticRegression(max_iter=200))]
        )
        X = np.zeros((10, 1))
        y = np.array([0, 1] * 5)
        pipe.fit(X, y)
        return pipe, []

    # Feature selection
    try:
        feature_cols = _select_feature_columns(df)
    except Exception:
        # Fallback: use any numeric columns
        feature_cols = sorted(df.select_dtypes(include=[np.number]).columns.tolist())

    # Synthetic label: approve if (DTI < 0.45) & (income above median)
    dti = _infer_dti(df)
    income = pd.to_numeric(df.get("income", 0.0), errors="coerce").fillna(0.0)
    income_thresh = float(np.nanmedian(income)) if len(income) else 0.0
    y = ((dti < 0.45) & (income >= income_thresh)).astype(int).to_numpy()

    # Ensure both classes exist; if not, flip a few to create separation
    if len(np.unique(y)) == 1:
        idx = np.random.default_rng(42).choice(len(y), size=max(1, len(y) // 10), replace=False)
        y[idx] = 1 - y[idx]

    X = df.reindex(columns=feature_cols, fill_value=0.0).to_numpy(dtype=float)

    pipe = Pipeline(
        steps=[("scaler", StandardScaler(with_mean=False)),
               ("clf", LogisticRegression(max_iter=400, class_weight="balanced"))]
    )
    pipe.fit(X, y)
    return pipe, feature_cols
