import io, os, json, uuid, time, requests, tempfile
from typing import Optional, Dict, Any
from enum import Enum

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
import pandas as pd
import sys

# ──────────────────────────────────────────────────────────────
# PATH SETUP
APP_DIR = os.path.dirname(__file__)
ROOT = os.path.abspath(os.path.join(APP_DIR, "../../"))
sys.path.append(ROOT)

from agent_platform.agent_sdk.sdk import load_agent

RUNS_DIR = os.path.join(APP_DIR, ".runs")
os.makedirs(RUNS_DIR, exist_ok=True)

OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "phi3")

app = FastAPI(title="Demo Agent API", version="0.4.0 (dropdown formats)")
RUNS: Dict[str, Dict[str, Any]] = {}

# ──────────────────────────────────────────────────────────────
# VALIDATION AND MASKING UTILITIES
class ValidateSchemaReq(BaseModel):
    columns: list[str]

BANNED_COLUMNS = {"race", "gender", "religion", "ethnicity", "ssn", "national_id"}
PII_LIKE = {"name", "email", "phone", "address", "ssn", "national_id"}

def basic_mask(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in df.columns:
        lower = col.lower()
        if any(key in lower for key in PII_LIKE):
            df[col] = "***MASKED***"
    return df

def policy_validate_columns(columns: list[str]):
    banned_found = BANNED_COLUMNS.intersection({c.lower() for c in columns})
    if banned_found:
        raise HTTPException(400, detail=f"Schema rejected by policy (banned columns: {sorted(banned_found)})")

def save_temp_csv(df: pd.DataFrame) -> str:
    path = os.path.join(RUNS_DIR, f"upload_{uuid.uuid4().hex}.csv")
    df.to_csv(path, index=False)
    return path

# ──────────────────────────────────────────────────────────────
# LLM SUMMARY GENERATION
def gen_narrative_with_ollama(summary: dict, top_explanations: list[dict], timeout=30):
    if not OLLAMA_MODEL:
        return None
    lines = []
    for x in top_explanations[:8]:
        try:
            score = float(x.get("score", 0.0))
        except Exception:
            score = 0.0
        lines.append(f"{x.get('application_id')} | {x.get('decision')} | score {score:.2f} | because {x.get('explanation')}")
    prompt = f"""
You are generating a concise managerial summary from credit scoring outcomes.

Summary:
- total: {summary.get('count')}
- approved: {summary.get('approved')}
- denied: {summary.get('denied')}

Top individual reasons:
{chr(10).join(lines)}

Write 3-5 bullet points:
- One overall trend
- Two key factors driving approvals vs denials
- One caution/risk note
Be concise, neutral, and avoid any PII.
"""
    try:
        r = requests.post(
            f"{OLLAMA_HOST}/v1/chat/completions",
            json={
                "model": OLLAMA_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 250,
                "stream": False
            },
            timeout=timeout
        )
        r.raise_for_status()
        data = r.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception:
        try:
            r = requests.post(
                f"{OLLAMA_HOST}/api/generate",
                json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False},
                timeout=timeout
            )
            r.raise_for_status()
            data = r.json()
            return data.get("response", "").strip()
        except Exception as e2:
            print(f"[narrative/ollama] failed: {e2}")
            return None

# ──────────────────────────────────────────────────────────────
# MAIN ROUTES
@app.get("/v1/datasets")
def list_datasets():
    return {"datasets": [{"id": "credit_sample", "path": "samples/credit/sample.csv", "rows": 500}]}

@app.post("/v1/validate-schema")
def validate_schema(req: ValidateSchemaReq):
    policy_validate_columns(req.columns)
    return {"ok": True}

@app.post("/v1/agents/{agent_name}/run")
async def run_agent(
    agent_name: str,
    use_sample: bool = Form(default=False),
    schema_json: Optional[str] = Form(default=None),
    file: Optional[UploadFile] = File(default=None),
    use_llm_narrative: bool = Form(default=True)
):
    if agent_name != "credit_appraisal":
        raise HTTPException(404, "Agent not found")

    # Load dataset
    if use_sample:
        csv_path = os.path.join(ROOT, "samples", "credit", "sample.csv")
        df = pd.read_csv(csv_path)
    else:
        if file is None:
            raise HTTPException(400, "Provide file or use_sample=true")
        content = await file.read()
        df = pd.read_csv(io.BytesIO(content))

    # Schema & policy
    policy_validate_columns(df.columns.tolist())
    if schema_json:
        try:
            schema = json.loads(schema_json)
            required = set(schema.get("required", []))
            if required and not required.issubset(df.columns):
                missing = required - set(df.columns)
                raise HTTPException(400, f"Schema missing required columns: {sorted(missing)}")
        except json.JSONDecodeError:
            raise HTTPException(400, "schema_json invalid")

    df_masked = basic_mask(df)
    tmp_csv = save_temp_csv(df_masked)

    run_id = f"run_{uuid.uuid4().hex}"
    RUNS[run_id] = {"id": run_id, "agent": agent_name, "status": "queued", "logs": [], "artifacts": {}}
    def log(msg): RUNS[run_id]["logs"].append({"t": time.time(), "msg": msg}); print(f"[{run_id}] {msg}")

    try:
        RUNS[run_id]["status"] = "running"
        log("loading agent...")
        agent = load_agent(os.path.join(ROOT, "agents", "credit_appraisal"))
        log("executing agent...")

        narrative = None
        if use_llm_narrative:
            narrative = gen_narrative_with_ollama({"count": len(df_masked), "approved": None, "denied": None}, [])
        out = agent.run({"applications_csv": tmp_csv}, ctx={"run_id": run_id, "narrative": narrative})

        if use_llm_narrative:
            narrative = gen_narrative_with_ollama(out.get("summary", {}), out.get("explanations", [])[:10])
            if narrative:
                out["narrative"] = narrative

        RUNS[run_id]["artifacts"] = out.get("artifacts", {})
        RUNS[run_id]["result"] = {k: v for k, v in out.items() if k != "artifacts"}
        RUNS[run_id]["status"] = "succeeded"
        return {"run_id": run_id, **RUNS[run_id]}
    except Exception as e:
        RUNS[run_id]["status"] = "failed"
        RUNS[run_id]["error"] = str(e)
        raise HTTPException(500, f"Agent failed: {e}")
    finally:
        try: os.remove(tmp_csv)
        except Exception: pass

@app.get("/v1/runs/{run_id}")
def get_run(run_id: str):
    run = RUNS.get(run_id)
    if not run:
        raise HTTPException(404, "Run not found")
    return run

# ──────────────────────────────────────────────────────────────
# ENUM FOR SWAGGER DROPDOWN
class ReportFormat(str, Enum):
    pdf = "pdf"
    scores_csv = "scores_csv"
    explanations_csv = "explanations_csv"
    csv = "csv"     # merged CSV (scores + explanations)
    json = "json"   # structured result JSON

# ──────────────────────────────────────────────────────────────
# MULTI-FORMAT DOWNLOAD (PDF, CSV, JSON) — with dropdown in Swagger
@app.get("/v1/runs/{run_id}/report")
def get_report(
    run_id: str,
    format: ReportFormat = Query(
        ReportFormat.pdf,
        description="Choose the output format to download."
    )
):
    """
    Download output for a given run in multiple formats.
    - pdf → credit report
    - scores_csv → model scores
    - explanations_csv → SHAP explanations
    - csv → merged CSV (scores + explanations)
    - json → structured JSON result
    """
    run = RUNS.get(run_id)
    if not run or run.get("status") != "succeeded":
        raise HTTPException(404, "Run not available")

    artifacts = run.get("artifacts", {})
    if not artifacts:
        raise HTTPException(404, "No artifacts found")

    # JSON output
    if format == ReportFormat.json:
        result = run.get("result", {})
        return JSONResponse(content=result)

    # Merge CSVs on demand
    if format == ReportFormat.csv:
        scores_path = artifacts.get("scores_csv")
        explanations_path = artifacts.get("explanations_csv")
        if not scores_path or not os.path.exists(scores_path):
            raise HTTPException(404, "scores_csv missing")
        if not explanations_path or not os.path.exists(explanations_path):
            raise HTTPException(404, "explanations_csv missing")

        df_scores = pd.read_csv(scores_path)
        df_expl = pd.read_csv(explanations_path)
        if "application_id" in df_scores.columns and "application_id" in df_expl.columns:
            merged = pd.merge(df_scores, df_expl, on="application_id", suffixes=("_score", "_explain"))
        else:
            merged = pd.concat([df_scores, df_expl], axis=1)

        temp_path = os.path.join(tempfile.gettempdir(), f"merged_{run_id}.csv")
        merged.to_csv(temp_path, index=False)
        return FileResponse(temp_path, media_type="text/csv", filename=f"merged_{run_id}.csv")

    # Existing formats
    if format == ReportFormat.pdf:
        path = artifacts.get("explanation_pdf")
        content_type = "application/pdf"
    elif format == ReportFormat.scores_csv:
        path = artifacts.get("scores_csv")
        content_type = "text/csv"
    elif format == ReportFormat.explanations_csv:
        path = artifacts.get("explanations_csv")
        content_type = "text/csv"
    else:
        raise HTTPException(400, f"Unsupported format: {format}")

    if not path or not os.path.exists(path):
        raise HTTPException(404, f"{format.value if isinstance(format, ReportFormat) else format} file not found")

    return FileResponse(path, media_type=content_type, filename=os.path.basename(path))
