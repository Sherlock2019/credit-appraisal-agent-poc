# agents/credit_appraisal/model_utils.py
from __future__ import annotations
import os
import time
import json
import joblib
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

THIS_DIR = os.path.dirname(__file__)
MODELS_DIR = os.path.join(THIS_DIR, "models")
TRAINED_DIR = os.path.join(MODELS_DIR, "trained")
PROD_DIR = os.path.join(MODELS_DIR, "production")
os.makedirs(TRAINED_DIR, exist_ok=True)
os.makedirs(PROD_DIR, exist_ok=True)

FEATURES = [
    "income",
    "loan_amount",
    "loan_term_months",
    "debt_to_income",
    "credit_score",
    "employment_years",
    "credit_history_length",
    "num_delinquencies",
    "current_loans",
    "assets_owned",
    "collateral_value",
]

DEFAULT_PROD_MODEL_PATH = os.path.join(PROD_DIR, "credit_model.joblib")
DEFAULT_PROD_META_PATH = os.path.join(PROD_DIR, "meta.json")

def _prep(df: pd.DataFrame) -> pd.DataFrame:
    # fill missing / clip sensibly
    out = df.copy()
    for c in FEATURES:
        if c not in out.columns:
            out[c] = 0
    out = out[FEATURES].copy()
    for c in out.columns:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0.0)
    return out

def ensure_production_model(df_hint: pd.DataFrame | None = None):
    if os.path.exists(DEFAULT_PROD_MODEL_PATH):
        try:
            model = joblib.load(DEFAULT_PROD_MODEL_PATH)
            return model
        except Exception:
            pass
    # Train a tiny baseline from df_hint if available; otherwise fabricate simple separable labels
    X = _prep(df_hint if df_hint is not None else pd.DataFrame(columns=FEATURES))
    if X.empty:
        X = pd.DataFrame(np.zeros((100, len(FEATURES))), columns=FEATURES)
    rng = np.random.default_rng(0)
    # synthetic label: lower DTI & higher credit_score more likely approved
    dti = X.get("debt_to_income", pd.Series(np.zeros(len(X)))).values
    cs  = X.get("credit_score", pd.Series(np.zeros(len(X)))).values
    y = ((cs > 620) & (dti < 0.5)).astype(int)
    model = LogisticRegression(max_iter=200)
    try:
        model.fit(X, y)
    except Exception:
        # in degenerate cases fit might fail; train on synthetic grid
        Z = pd.DataFrame({
            "debt_to_income": np.linspace(0, 1, 200),
            "credit_score": np.linspace(300, 850, 200),
        })
        for c in FEATURES:
            if c not in Z.columns:
                Z[c] = 0.0
        y2 = ((Z["credit_score"] > 620) & (Z["debt_to_income"] < 0.5)).astype(int)
        model.fit(Z[FEATURES], y2)
    joblib.dump(model, DEFAULT_PROD_MODEL_PATH)
    with open(DEFAULT_PROD_META_PATH, "w") as f:
        json.dump({"version": time.time(), "source": "bootstrap"}, f)
    return model

def predict_proba(model, df: pd.DataFrame) -> np.ndarray:
    X = _prep(df)
    try:
        p = model.predict_proba(X)[:, 1]
    except Exception:
        # Fallback: linear-ish score if model lacks predict_proba
        dti = X["debt_to_income"].clip(0, 1).values
        cs = X["credit_score"].clip(300, 850).values
        norm_cs = (cs - 300) / (850 - 300 + 1e-9)
        p = (0.6 * norm_cs + 0.4 * (1 - dti)).clip(0, 1)
    return p

def train_candidate_from_review(reviewed_csv: str | None,
                                ai_output_paths: list[str],
                                cutoff_date: str | None) -> dict:
    # Build a simple supervised set: prefer reviewed CSV (human_decision), otherwise infer from AI outputs if possible.
    frames = []
    if reviewed_csv and os.path.exists(reviewed_csv):
        df = pd.read_csv(reviewed_csv)
        # Expect columns: application_id, ai_decision, human_decision
        if "human_decision" in df.columns:
            df["label"] = (df["human_decision"].astype(str).str.lower() == "approved").astype(int)
            frames.append(df)
    for p in ai_output_paths or []:
        if os.path.exists(p):
            d = pd.read_csv(p)
            if "decision" in d.columns:
                d = d.copy()
                d["label"] = (d["decision"].astype(str).str.lower() == "approved").astype(int)
                frames.append(d)

    if not frames:
        # No data, return noop
        return {"job_id": f"job_{int(time.time())}", "metrics": {}}

    data = pd.concat(frames, ignore_index=True)
    X = _prep(data)
    y = pd.to_numeric(data["label"], errors="coerce").fillna(0).astype(int)

    # Simple train/holdout split
    idx = np.arange(len(X))
    rng = np.random.default_rng(0)
    rng.shuffle(idx)
    split = int(0.8 * len(idx))
    tr, te = idx[:split], idx[split:]
    Xtr, ytr = X.iloc[tr], y.iloc[tr]
    Xte, yte = X.iloc[te], y.iloc[te]

    model = LogisticRegression(max_iter=500)
    model.fit(Xtr, ytr)
    pred = model.predict(Xte)
    acc = float(accuracy_score(yte, pred))
    job_id = f"job_{int(time.time())}"

    # Save candidate
    cand_path = os.path.join(TRAINED_DIR, f"candidate_{job_id}.joblib")
    cand_meta = os.path.join(TRAINED_DIR, f"candidate_{job_id}.json")
    os.makedirs(TRAINED_DIR, exist_ok=True)
    joblib.dump(model, cand_path)
    with open(cand_meta, "w") as f:
        json.dump({"job_id": job_id, "accuracy": acc, "timestamp": time.time()}, f)
    return {"job_id": job_id, "metrics": {"accuracy": acc, "size": len(X)}}

def promote_candidate_to_production() -> dict | None:
    # pick most recent candidate
    files = [f for f in os.listdir(TRAINED_DIR) if f.startswith("candidate_") and f.endswith(".joblib")]
    if not files:
        return None
    files = sorted(files, reverse=True)
    src_model = os.path.join(TRAINED_DIR, files[0])
    meta_json = src_model.replace(".joblib", ".json")
    os.makedirs(PROD_DIR, exist_ok=True)
    # copy model
    import shutil
    shutil.copyfile(src_model, DEFAULT_PROD_MODEL_PATH)
    meta = {"version": time.time(), "source": "candidate"}
    if os.path.exists(meta_json):
        try:
            with open(meta_json) as f:
                m = json.load(f)
            meta.update(m)
        except Exception:
            pass
    with open(DEFAULT_PROD_META_PATH, "w") as f:
        json.dump(meta, f)
    return meta

def get_production_meta() -> dict:
    if not os.path.exists(DEFAULT_PROD_MODEL_PATH):
        return {"has_production": False}
    meta = {}
    if os.path.exists(DEFAULT_PROD_META_PATH):
        try:
            meta = json.load(open(DEFAULT_PROD_META_PATH))
        except Exception:
            meta = {}
    return {"has_production": True, "meta": meta}
