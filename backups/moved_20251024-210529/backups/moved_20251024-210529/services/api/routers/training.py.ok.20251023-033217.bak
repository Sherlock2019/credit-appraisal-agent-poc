# services/api/routers/training.py
from __future__ import annotations

import os
import glob
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException, Body
from fastapi.responses import JSONResponse

from agents.credit_appraisal import model_utils as MU

router = APIRouter(prefix="/v1/training", tags=["training"])

RUNS_DIR = os.path.expanduser("~/demo-library/services/api/.runs")
os.makedirs(RUNS_DIR, exist_ok=True)

# ─────────────────────────────────────────────
# List available models (for UI dropdown)

@router.get("/models")
def list_models():
    """
    Returns:
      {
        "production": {...},
        "trained": [{"filename","path","mtime","display"}, ...]
      }
    """
    return JSONResponse(MU.list_available_models())


# ─────────────────────────────────────────────
# Simple production meta

@router.get("/production_meta")
def production_meta():
    meta = {"has_production": False, "meta": {}}
    if os.path.exists(MU.PRODUCTION_MODEL_PATH):
        meta["has_production"] = True
        meta["meta"] = MU._read_json(MU.PRODUCTION_META_PATH)
    return JSONResponse(meta)

# ─────────────────────────────────────────────
# Feedback → Train a candidate

@router.post("/train")
def train_candidate(payload: Dict[str, Any] = Body(...)):
    """
    Body (example):
      {
        "feedback_csvs": ["/full/path/feedback_1.csv", "..."]  # optional; you can also glob .runs
        "user_name": "dzoan",                                  # for filename scheme
        "agent_name": "credit_appraisal",                       # default if missing
        "algo_name": "credit_lr"                                # default if missing
      }
    If feedback_csvs is missing, we try to glob recent feedback under .runs.
    """
    feedback_csvs: Optional[List[str]] = payload.get("feedback_csvs")
    user_name: str = payload.get("user_name") or "user"
    agent_name: str = payload.get("agent_name") or MU.DEFAULT_AGENT_NAME
    algo_name: str = payload.get("algo_name") or MU.DEFAULT_ALGO_NAME

    if not feedback_csvs:
        # Fallback: any CSVs that look like feedback under .runs
        feedback_csvs = glob.glob(os.path.join(RUNS_DIR, "**", "feedback*.csv"), recursive=True)
        if not feedback_csvs:
            raise HTTPException(status_code=400, detail="No feedback CSVs provided or discovered under .runs.")

    try:
        model, metrics = MU.fit_candidate_on_feedback(feedback_csvs)
        meta = MU.save_trained_model(model, username=user_name, agent_name=agent_name, algo_name=algo_name, extra_meta=metrics)
        return JSONResponse({"status": "ok", "job_id": meta["filename"], "metrics": metrics, "meta": meta})
    except ValueError as ve:
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Training failed: {e}")

# ─────────────────────────────────────────────
# Promote last candidate → production

@router.post("/promote")
def promote_latest_trained():
    trained = sorted(glob.glob(os.path.join(MU.TRAINED_DIR, "*.joblib")), key=os.path.getmtime, reverse=True)
    if not trained:
        raise HTTPException(status_code=400, detail="No trained models found.")
    latest = trained[0]
    try:
        model = MU.joblib.load(latest)  # same module
    except Exception:
        model = MU.load_active_model()  # fallback

    meta = MU.save_as_production(model, {"source": "trained", "from_file": os.path.basename(latest)})
    return JSONResponse({"status": "ok", "production": meta})
